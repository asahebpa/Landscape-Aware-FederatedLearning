{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset, TensorDataset  \n",
    "torch.backends.cudnn.benchmark=True\n",
    "from pyhessian import hessian # Hessian computation\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 784)\n",
    "        self.hidden2 = nn.Linear(784, 600)\n",
    "        self.hidden3 = nn.Linear(600, 400)\n",
    "        self.hidden4 = nn.Linear(400, 200)\n",
    "        # Output layer, 62 units \n",
    "        self.output = nn.Linear(200, 26)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.ReLu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = torch.reshape(x, (-1, 784))\n",
    "        x = self.hidden(x)\n",
    "        x = self.ReLu(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.ReLu(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.ReLu(x)\n",
    "        x = self.hidden4(x)\n",
    "        x = self.ReLu(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_update(client_model, optimizer, train_loader, mode, epoch=5):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data\n",
    "    \"\"\"\n",
    "    client_model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (inputs, target) in enumerate(train_loader):\n",
    "            inputs, target = inputs.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(inputs)\n",
    "            loss = nn.functional.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    if mode == 'Average':\n",
    "        return loss.item()\n",
    "    if mode == 'HessFuse':\n",
    "        client_model.eval()\n",
    "        for batch_idx, (inputs, target) in enumerate(train_loader):\n",
    "                inputs, target = inputs.cuda(), target.cuda()\n",
    "                loss2 = torch.nn.CrossEntropyLoss()\n",
    "                hessian_comp = hessian(client_model, loss2, data=(inputs, target), cuda=True)\n",
    "                top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()\n",
    "                break\n",
    "\n",
    "        return loss.item(), top_eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate(global_model, client_models, weights):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([(weights[0]*(client_models[0].state_dict()[k].float())) for i in range(len(client_models))], 0).mean(0)\n",
    "            \n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(global_model, test_loader):\n",
    "    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\n",
    "    global_model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "#             target = torch.nn.functional.one_hot(target)\n",
    "            output = global_model(data)\n",
    "            test_loss += nn.functional.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            count += 1\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 100\n",
    "num_selected = 100\n",
    "num_rounds = 20\n",
    "epochs = 5\n",
    "batch_size = 100\n",
    "random.seed(13)\n",
    "np.random.seed(13)\n",
    "torch.manual_seed(13)\n",
    "\n",
    "mat = scipy.io.loadmat('./dataset/emnist-letters.mat')\n",
    "data = mat[\"dataset\"]\n",
    "writer_ids_train = data['train'][0,0]['writers'][0,0]\n",
    "writer_ids_train = np.squeeze(writer_ids_train)\n",
    "X_train = data['train'][0,0]['images'][0,0]\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28), order = \"F\")\n",
    "y_train = data['train'][0,0]['labels'][0,0]\n",
    "y_train = np.squeeze(y_train)\n",
    "y_train -= 1 #y_train is zero-based\n",
    "indtemp = list()\n",
    "vec = writer_ids_train%num_clients\n",
    "for i in range(num_clients):\n",
    "    indi = np.where(vec == i)\n",
    "    indtemp.append(list(indi[0]))\n",
    "\n",
    "train_loader = [torch.utils.data.DataLoader(TensorDataset(torch.FloatTensor(X_train[indtemp[i]][:][:]), torch.LongTensor(y_train[indtemp[i]][:][:])), batch_size=batch_size, shuffle=True) for i in range(num_clients)]\n",
    "    \n",
    "\n",
    "writer_ids_test = data['test'][0,0]['writers'][0,0]\n",
    "writer_ids_test = np.squeeze(writer_ids_test)\n",
    "X_test = data['test'][0,0]['images'][0,0]\n",
    "X_test= X_test.reshape((X_test.shape[0], 28, 28), order = \"F\")\n",
    "y_test = data['test'][0,0]['labels'][0,0]\n",
    "y_test = np.squeeze(y_test)\n",
    "y_test -= 1 #y_test is zero-based\n",
    "test_loader = torch.utils.data.DataLoader(TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test)), batch_size=batch_size, shuffle=True)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:04<00:13,  5.41it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.73 GiB total capacity; 993.02 MiB already allocated; 16.06 MiB free; 1.04 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-25b2cff9bc9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0meigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Average'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mlosstot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7afb8f58cdc9>\u001b[0m in \u001b[0;36mclient_update\u001b[0;34m(client_model, optimizer, train_loader, mode, epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Average'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/second/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/second/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     89\u001b[0m                         \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                         \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg_sq'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amsgrad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                             \u001b[0;31m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.73 GiB total capacity; 993.02 MiB already allocated; 16.06 MiB free; 1.04 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "#### Initializing models and optimizer  ####\n",
    "############################################\n",
    "\n",
    "# #### global model ##########\n",
    "# global_model =  VGG('VGG19').cuda()\n",
    "global_model =  Network().cuda()\n",
    "# ############## client models ##############\n",
    "# client_models = [ VGG('VGG19').cuda() for _ in range(num_selected)]\n",
    "client_models = [ Network().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \n",
    "\n",
    "############### optimizers ################\n",
    "opt = [optim.Adam(model.parameters(), lr=0.00001) for model in client_models]\n",
    "\n",
    "\n",
    "###### List containing info about learning #########\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "# Runnining FL\n",
    "mode = 'Average'\n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "    # client update\n",
    "    losstot = 0\n",
    "    eigs = np.ones(num_selected)\n",
    "    for i in tqdm(range(num_selected)):\n",
    "        if mode == 'HessFuse':\n",
    "            loss, eigss = client_update(client_models[client_idx[i]], opt[client_idx[i]], train_loader[client_idx[i]], mode, epoch=epochs)\n",
    "            eigs[i] = eigss[0]\n",
    "        if mode == 'Average':\n",
    "            loss = client_update(client_models[client_idx[i]], opt[client_idx[i]], train_loader[client_idx[client_idx[i]]], mode, epoch=epochs)\n",
    "        losstot += loss\n",
    "        \n",
    "    weights = eigs/(np.sum(eigs))\n",
    "    losses_train.append(loss)\n",
    "    # server aggregate\n",
    "    server_aggregate(global_model, client_models, weights*num_selected)\n",
    "    \n",
    "    test_loss, acc = test(global_model.eval(), test_loader)\n",
    "    losses_test.append(test_loss)\n",
    "    acc_test.append(acc)\n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# choose = (random.randrange(len(datareally['y'])))\n",
    "\n",
    "# datareally = (dd['f1816_24'])\n",
    "# x1 = datareally['x'][choose]\n",
    "# print(datareally['y'][choose])\n",
    "\n",
    "# import numpy as np\n",
    "# x1 = np.zeros((784,63))\n",
    "# counters = np.zeros((63))\n",
    "# print(x1.shape)\n",
    "# for i in range(len(datareally['y'])):\n",
    "#     print(np.array(datareally['x'][i]).shape)\n",
    "#     label = datareally['y'][i]\n",
    "#     counters[label] += 1 \n",
    "#     x1[:, label] += np.array(datareally['x'][i])\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "# for i,ax in enumerate(axes.flat):\n",
    "#     tempol = x1[:, i]/counters[i]\n",
    "#     xplot = np.reshape(np.ravel(tempol), (28, 28))\n",
    "#     ax.imshow(xplot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:second]",
   "language": "python",
   "name": "conda-env-second-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
